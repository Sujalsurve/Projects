# Data-Science projects 
1]Churn Data Analysis Project: Summary
  Objective: Analyze customer churn data to predict and reduce churn using SQL, Excel, Machine Learning, and Power BI.

   1. ETL-extraction,transformation,loading data (SQL):
  Extract churn-related data (e.g., customer demographics, usage, support interactions) from a relational database using SQL queries.

   3. Data Cleaning & Preparation (Excel):
   Clean and transform data by handling missing values, encoding categorical variables, and creating new features in Excel. Perform basic statistical analysis to understand the data.

  5. Predictive Modeling (Machine Learning):
  Use machine learning algorithm ( Random Forest) to predict future churners . Evaluate model perfomance using confusion matrix,feature selection.

  7. Data Visualization (Power BI):
  Import data into Power BI and create interactive dashboards to visualize churn trends, customer segments, and key factors contributing to churn. Display predicted churn likelihood and allow dynamic filtering of 
  data.

  9. Insights & Recommendations:
  Identify at-risk customers and suggest targeted retention strategies. Highlight factors that contribute most to churn and offer actionable recommendations for improvement.
  Outcome: A comprehensive churn analysis that combines data extraction, predictive modeling, and visualization to help improve customer retention.

  Tools Used: Microsoft sql server, Excel for data preparation, Machine Learning for predictions, and Power BI for visualization.

2] Power bi projects-
   
  1 Madhav stores Data visualization

  2 worldcup 2022 best 11 players analysis 


3] Zomato clone website -
   made a zomato clone website using html and css create the homepage.

4] Uber ETL pipeline using Mage and GCP cloud: Designed and implemented an efficient Uber ETL pipeline utilizing 
   Mage for data orchestration and GCP (Google Cloud Platform) services for scalability and reliability. Leveraged Mage's 
   intuitive interface to build, monitor, and optimize data workflows while integrating GCP components such as Big Query, 
   Cloud Storage, and Pub/Sub for seamless data ingestion, processing, and storage.

5] Amazon webscrapping project : used beautiful soap library to extract the data from the amazon e-commerce website and then
   performed ETL and EDA process using python libraries.



  
   
  
